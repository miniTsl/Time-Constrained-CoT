{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_dir = \"/data03/sunyi/time_constrained_cot/outputs/2_6\"\n",
    "latency_path = \"/home/sunyi/CoT/Time-Constrained-CoT/latency/0210\"\n",
    "model_list = [\n",
    "    \"Qwen/QwQ-32B-Preview\",\n",
    "    # \"Skywork/Skywork-o1-Open-Llama-3.1-8B\", \n",
    "    # \"PowerInfer/SmallThinker-3B-Preview\",\n",
    "    \"NovaSky-AI/Sky-T1-32B-Preview\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    \"Qwen/Qwen2.5-Math-1.5B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-Math-7B-Instruct\",\n",
    "    \"mistralai/Mathstral-7B-v0.1\",\n",
    "    \"Qwen/Qwen2.5-32B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"mistralai/Mistral-Small-Instruct-2409\",\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    \"microsoft/Phi-3-medium-128k-instruct\",\n",
    "    \"microsoft/Phi-3-small-128k-instruct\",\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    \"microsoft/Phi-3.5-mini-instruct\",\n",
    "    \"microsoft/phi-4\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMP_LIST = [ \"-aav\", \"-c2f\", \"-sbs\"]\n",
    "\n",
    "\n",
    "MODEL_SERIES_MAP = {\n",
    "    \"Qwen/QwQ-32B-Preview\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-32B-Instruct\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-14B-Instruct\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\": \"qwen\",\n",
    "    \"Qwen/Qwen2.5-Math-1.5B-Instruct\": \"qwen-math\",\n",
    "    \"Qwen/Qwen2.5-Math-7B-Instruct\": \"qwen-math\",\n",
    "    \"internlm/internlm2_5-1_8b-chat\": \"internlm\",\n",
    "    \"internlm/internlm2_5-7b-chat\": \"internlm\",\n",
    "    \"internlm/internlm2_5-20b-chat\": \"internlm\",\n",
    "    \"google/gemma-2-2b-it\": \"gemma\",\n",
    "    \"google/gemma-2-9b-it\": \"gemma\",\n",
    "    \"google/gemma-2-27b-it\": \"gemma\",\n",
    "    \"mistralai/Mathstral-7B-v0.1\": \"mistral\",\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\": \"mistral\",\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\": \"mistral\",\n",
    "    \"mistralai/Mistral-Small-Instruct-2409\": \"mistral\",\n",
    "    \"microsoft/phi-4\": \"phi4\",\n",
    "    \"microsoft/Phi-3-medium-128k-instruct\": \"phi3medium\",\n",
    "    \"microsoft/Phi-3-small-128k-instruct\": \"phi3small\",\n",
    "    \"microsoft/Phi-3.5-mini-instruct\": \"phi3mini\",\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\": \"phi3mini\",\n",
    "    \"NovaSky-AI/Sky-T1-32B-Preview\": \"qwen\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": \"deepseek-r1-distill\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": \"deepseek-r1-distill\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": \"deepseek-r1-distill\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": \"deepseek-r1-distill\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": \"deepseek-r1-distill\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\": \"llama\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\": \"llama\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": \"llama\"\n",
    "}\n",
    "\n",
    "\n",
    "MODEL_SERIES_PROMPT_TYPE_MAP = {\n",
    "    \"qwen\": [\"qwen\" + prompt for prompt in PROMP_LIST],\n",
    "    \"qwen-math\": [\"qwen-math\" + prompt for prompt in PROMP_LIST],\n",
    "    \"internlm\": [\"internlm\"+prompt for prompt in PROMP_LIST],\n",
    "    \"mistral\": [\"mistral\"+prompt for prompt in PROMP_LIST],\n",
    "    \"gemma\": [\"gemma\"+prompt for prompt in PROMP_LIST],\n",
    "    \"phi3mini\": [\"phi3mini\"+prompt for prompt in PROMP_LIST],\n",
    "    \"phi3small\": [\"phi3small\"+prompt for prompt in PROMP_LIST],\n",
    "    \"phi3medium\": [\"phi3medium\"+prompt for prompt in PROMP_LIST],\n",
    "    \"phi4\": [\"phi4\"+prompt for prompt in PROMP_LIST],\n",
    "    \"deepseek-r1-distill\": [\"deepseek-r1-distill\"+prompt for prompt in PROMP_LIST],\n",
    "    \"llama\": [\"llama\"+prompt for prompt in PROMP_LIST]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gsm8k\"\n",
    "something = \"_-1_seed0_t0.0_s0_e-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen/Qwen2.5-7B-Instruct qwen-aav 5.0 83.82753808344151\n",
      "Qwen/Qwen2.5-7B-Instruct qwen-aav 5.5 85.29591794373331\n",
      "microsoft/phi-4 phi4-aav 6.0 87.42298335270809\n",
      "microsoft/phi-4 phi4-aav 6.5 89.41359329937417\n",
      "microsoft/phi-4 phi4-aav 7.0 91.15355751763327\n",
      "microsoft/phi-4 phi4-aav 7.5 92.1863189259525\n",
      "microsoft/phi-4 phi4-aav 8.0 93.02408679666124\n",
      "microsoft/phi-4 phi4-aav 8.5 93.42571623322982\n",
      "microsoft/phi-4 phi4-aav 9.0 93.69743385848503\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-aav 9.5 93.94531029854866\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-aav 10.0 94.30290467861026\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 10.5 94.62514654444826\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 11.0 94.99170259299892\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 11.5 95.23610155019324\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 12.0 95.41610010147751\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 12.5 95.46497989291638\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 13.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 13.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 14.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 14.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 15.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 15.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 16.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 16.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 17.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 17.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 18.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 18.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 19.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 19.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 20.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 20.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 21.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 21.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 22.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 22.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 23.0 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 23.5 95.5\n",
      "Qwen/Qwen2.5-Math-7B-Instruct qwen-math-c2f 24.0 95.5\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 24.5 95.69162376862701\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 25.0 95.8960759945215\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 25.5 95.99086107087128\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 26.0 95.97227450488087\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 26.5 95.95368793889047\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 27.0 95.93510137290005\n",
      "NovaSky-AI/Sky-T1-32B-Preview qwen-sbs 27.5 95.94253292327059\n",
      "NovaSky-AI/Sky-T1-32B-Preview qwen-sbs 28.0 95.9957430108646\n",
      "NovaSky-AI/Sky-T1-32B-Preview qwen-sbs 28.5 95.97711925254686\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 29.0 95.97848978212316\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 29.5 96.01566291410398\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 30.0 96.05283604608479\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 30.5 96.0900091780656\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 31.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 31.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 32.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 32.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 33.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 33.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 34.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 34.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 35.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 35.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 36.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 36.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 37.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 37.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 38.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 38.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 39.0 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 39.5 96.1\n",
      "Qwen/Qwen2.5-32B-Instruct qwen-sbs 40.0 96.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Select_latency = [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]  \n",
    "Select_latency = list(np.arange(5, 40.5, 0.5))\n",
    "\n",
    "df = pd.read_csv('paticular_latency.csv', names=['Model', 'Prompt_Type', 'Latency', 'Accuracy'])\n",
    "# print(df)\n",
    "\n",
    "for latency in Select_latency:\n",
    "    acc_list = []\n",
    "    acc0 = 0\n",
    "    for model in model_list:\n",
    "        for prompt_type in MODEL_SERIES_PROMPT_TYPE_MAP[MODEL_SERIES_MAP[model]]:\n",
    "            # print(model, prompt_type, latency)\n",
    "            acc = df[(df['Model'] == model) & (df['Prompt_Type'] == prompt_type) & (df['Latency'] == str(latency))]['Accuracy'].values[0]\n",
    "            # print(acc)\n",
    "            acc_list.append(acc)\n",
    "    for acc in acc_list:\n",
    "        if float(acc) > float(acc0):\n",
    "            acc0 = acc\n",
    "    for model in model_list:\n",
    "        for prompt_type in MODEL_SERIES_PROMPT_TYPE_MAP[MODEL_SERIES_MAP[model]]:\n",
    "            try:\n",
    "                acc = df[(df['Model'] == model) & (df['Prompt_Type'] == prompt_type) & (df['Latency'] == str(latency)) & (df['Accuracy'] == str(acc0))]['Accuracy'].values[0]\n",
    "                print(model, prompt_type, latency, acc)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "\n",
    "# data = []\n",
    "\n",
    "# for model in model_spe_acc_dicts.keys():\n",
    "#     acc_dict = model_spe_acc_dicts[model]\n",
    "#     for prompt_type in model_spe_acc_dicts[model].keys():\n",
    "#         acc_list = acc_dict[prompt_type]\n",
    "#         for latency in acc_list.keys():\n",
    "#             data.append({\n",
    "#                 'Model': model,\n",
    "#                 'Prompt_Type': prompt_type,\n",
    "#                 'Latency': latency,\n",
    "#                 'Accuracy': acc_list[latency]\n",
    "#             })\n",
    "\n",
    "# # Convert to DataFrame and save\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('paticular_latency.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25_math_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
