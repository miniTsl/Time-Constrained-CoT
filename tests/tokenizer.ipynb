{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 29509,  1480,  1873,  5115, 29473, 29518, 17129,  1842,  1070,\n",
      "          5813, 19635,  1072,  3563,  1137,  1956,  3843, 19635, 29491, 29473,\n",
      "          2370,  2055, 17129,  1842,  1065,  3870,  2003,  1146,  2156, 29572],\n",
      "        [    1, 29509,  1480,  1873,  5115, 29473, 29518, 17129,  1842,  1070,\n",
      "          5813, 19635,  1072,  3563,  1137,  1956,  3843, 19635, 29491,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]])\n",
      "tensor([30, 19])\n",
      "tensor([25, 19])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in',\n",
       " 'A robe takes 2 bolts of blue fiber and half that much white fiber.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_budget = 25\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mathstral-7B-v0.1\", padding_side=\"right\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "full_cots = [\"A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\", \"A robe takes 2 bolts of blue fiber and half that much white fiber.\"]\n",
    "full_cots_tokens = tokenizer(full_cots, return_tensors=\"pt\", padding=True, ).input_ids\n",
    "print(full_cots_tokens)\n",
    "cot_lengths = (full_cots_tokens != tokenizer.pad_token_id).sum(dim=1)\n",
    "print(cot_lengths)\n",
    "truncate_lengths = torch.minimum(cot_lengths, torch.tensor(token_budget))\n",
    "print(truncate_lengths)\n",
    "mask = torch.arange(full_cots_tokens.shape[1])[None, :] < truncate_lengths[:, None]\n",
    "print(mask)\n",
    "# Apply mask to get truncated sequences\n",
    "part_cots_tokens = full_cots_tokens.masked_fill(~mask, tokenizer.pad_token_id)\n",
    "part_cots = tokenizer.batch_decode(part_cots_tokens, skip_special_tokens=True)\n",
    "part_cots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25_math_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
