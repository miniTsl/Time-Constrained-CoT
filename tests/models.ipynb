{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data03/sunyi/conda/envs/qwen25_math_eval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "checkpoint = \"mistralai/Mathstral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Please reason step by step, and put your final answer within \\boxed{{}}.\n",
      "\n",
      "A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?[/INST]\n",
      "<class 'str'>\n",
      "{'input_ids': tensor([[    1,     1,     3,  6687,  3379,  4475,  1254,  4475, 29493,  1072,\n",
      "          2426,  1342,  2248,  5140,  3141,  1182,  3626,  1054,  7420,  1743,\n",
      "         29491,   781,   781, 29509,  1480,  1873,  5115, 29473, 29518, 17129,\n",
      "          1842,  1070,  5813, 19635,  1072,  3563,  1137,  1956,  3843, 19635,\n",
      "         29491, 29473,  2370,  2055, 17129,  1842,  1065,  3870,  2003,  1146,\n",
      "          2156, 29572,     4]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content'] %}\n",
      "    {%- set loop_messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set loop_messages = messages %}\n",
      "{%- endif %}\n",
      "\n",
      "{{- bos_token }}\n",
      "{%- for message in loop_messages %}\n",
      "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
      "        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\n",
      "    {%- endif %}\n",
      "    {%- if message['role'] == 'user' %}\n",
      "        {%- if loop.last and system_message is defined %}\n",
      "            {{- '[INST] ' + system_message + '\\n\\n' + message['content'] + '[/INST]' }}\n",
      "        {%- else %}\n",
      "            {{- '[INST] ' + message['content'] + '[/INST]' }}\n",
      "        {%- endif %}\n",
      "    {%- elif message['role'] == 'assistant' %}\n",
      "        {{- ' ' + message['content'] + eos_token}}\n",
      "    {%- else %}\n",
      "        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Please reason step by step, and put your final answer within \\\\boxed{{}}.\"\n",
    "question = \"A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": question}]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "print(type(text))\n",
    "inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "print(inputs)\n",
    "print(tokenizer.chat_template)\n",
    "# prompt = question + \"\\nPlease reason step by step, and put your final answer within \\\\boxed{{}}.\" + \"1. The robe takes 2 bolts of blue fiber.\\n2. It takes half as much white fiber as blue fiber.\" + \"\\n\\nFinal answer within \\\\boxed{{}}:\\n\"\n",
    "# inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "# prompt = question + \"Solve the task through two types of reasoning:\\n1. Coarse-Grained Reasoning: give quick analysis step by step and an answer. Focus on efficiency and simplicity.\\n2. Fine-Grained Reasoning: give detailed analysis step by step and a refined answer. Foucus on accuracy and correctness.\\nPut final answer within \\\\boxed{{}}.\\n\\nOutput format:\\n**Coarse Reasoning**\\n\\n**Fine Reasoning**\\n\\n**Final Answer** within \\\\boxed{{}}\"\n",
    "# inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "# \"To solve this problem, we start by understanding that the robe requires 2 bolts of blue fiber. The problem states that the robe also requires half as much white fiber as blue fiber.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     3,  6687,  3379,  4475,  1254,  4475, 29493,  1072,\n",
      "          2426,  1342,  2248,  5140,  3141,  1182,  3626,  1054,  7420,  1743,\n",
      "         29491,   781,   781, 29509,  1480,  1873,  5115, 29473, 29518, 17129,\n",
      "          1842,  1070,  5813, 19635,  1072,  3563,  1137,  1956,  3843, 19635,\n",
      "         29491, 29473,  2370,  2055, 17129,  1842,  1065,  3870,  2003,  1146,\n",
      "          2156, 29572,     4,  2559, 12817,  1224,  3468, 29493,  1246,  1917,\n",
      "          1254,  7167,  1137,  1040,  1480,  1873,  7716, 29473, 29518, 17129,\n",
      "          1842,  1070,  5813, 19635, 29491,  1183,  3468,  5373,  1137,  1040,\n",
      "          1480,  1873,  1603,  7716,  3563,  1158,  1956,  3843, 19635,  1158,\n",
      "          5813, 19635, 29491,  9237, 29493,  1246, 14679,  1040,  4326,  1070,\n",
      "          3843, 19635,  4004,  1158,  6872, 29515,   781,   781, 29501,  3508,\n",
      "          1464,  1070,  3843, 19635,  1095,  1646,  2423, 29519, 29508,  2168,\n",
      "         29518, 29520,  1182,  5361, 29473, 29518, 29544, 17129,  1842,  1070,\n",
      "          5813, 19635,   781, 29501,  3508,  1464,  1070,  3843, 19635,  1095,\n",
      "          1197, 29508, 29544, 25378,  1070,  5813, 19635,   781,   781,  9247,\n",
      "         29493,  1066,  2068,  1040,  3870,  4326,  1070, 19635,  4004,  1122,\n",
      "          1040,  1480,  1873, 29493,  1246,  1735,  1040, 17129,  1842,  1070,\n",
      "          5813, 19635,  1072,  1040, 17129,  1842,  1070,  3843, 19635,  3321,\n",
      "         29515,   781,   781, 29501, 11479, 17129,  1842,  1070, 19635,  1095,\n",
      "         11591,  1842,  1070,  5813, 19635,  1416, 11591,  1842,  1070,  3843,\n",
      "         19635,   781, 29501, 11479, 17129,  1842,  1070, 19635,  1095,  1197,\n",
      "         29518,  1416, 29473, 29508, 29544,   781, 29501, 11479, 17129,  1842,\n",
      "          1070, 19635,  1095,  1197, 29538, 29544,   781,   781,  6584,  1762,\n",
      "         29493,  1040,  3870,  2242,  1070, 17129,  1842,  1070, 19635,  4004,\n",
      "          1122,  1040,  1480,  1873,  1117,  1646,  3626,  1054, 29519, 29538,\n",
      "          5892,     2]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s><s>[INST] Please reason step by step, and put your final answer within \\\\boxed{{}}.\\n\\nA robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?[/INST] To solve this problem, we start by understanding that the robe requires 2 bolts of blue fiber. The problem states that the robe also requires half as much white fiber as blue fiber. Therefore, we calculate the amount of white fiber needed as follows:\\n\\n- Amount of white fiber = $\\\\frac{1}{2} \\\\times 2$ bolts of blue fiber\\n- Amount of white fiber = $1$ bolt of blue fiber\\n\\nNow, to find the total amount of fiber needed for the robe, we add the bolts of blue fiber and the bolts of white fiber together:\\n\\n- Total bolts of fiber = Bolts of blue fiber + Bolts of white fiber\\n- Total bolts of fiber = $2 + 1$\\n- Total bolts of fiber = $3$\\n\\nTherefore, the total number of bolts of fiber needed for the robe is $\\\\boxed{3}$.</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "print(out)\n",
    "tokenizer.decode(out[0])\n",
    "\n",
    "# >>> '<s>[INST] What are the roots of unity?[/INST] The roots of unity are the complex numbers that satisfy the equation $z^n = 1$, where $n$ is a positive integer. These roots are evenly spaced around the unit circle in the complex plane, and they have a variety of interesting properties and applications in mathematics and physics.</s>'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25_math_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
