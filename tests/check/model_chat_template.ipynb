{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data03/sunyi/conda/envs/qwen25_math_eval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "model_list = [\n",
    "    # \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    # \"mistralai/Ministral-8B-Instruct-2410\",\n",
    "    # \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    # \"mistralai/Mistral-Small-Instruct-2409\",\n",
    "    # \"mistralai/Mathstral-7B-v0.1\",\n",
    "    \n",
    "    # \"Qwen/Qwen2.5-32B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-Math-1.5B-Instruct\",\n",
    "    # \"Qwen/Qwen2.5-Math-7B-Instruct\",\n",
    "    # \"Qwen/QwQ-32B-Preview\",\n",
    "    \n",
    "    # \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    # \"microsoft/Phi-3-small-128k-instruct\",\n",
    "    # \"microsoft/Phi-3-medium-128k-instruct\",\n",
    "    # \"microsoft/Phi-3.5-mini-instruct\",\n",
    "    # \"microsoft/phi-4\",\n",
    "    \n",
    "    # \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    # \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    # \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \n",
    "    # \"google/gemma-2-9b-it\",\n",
    "    # \"google/gemma-2-2b-it\",\n",
    "\n",
    "    # \"AI-MO/NuminaMath-7B-CoT\",\n",
    "\n",
    "    # \"internlm/internlm2_5-1_8b-chat\",\n",
    "    # \"internlm/internlm2_5-7b-chat\",\n",
    "    # \"internlm/internlm2_5-20b-chat\",\n",
    "    # \"internlm/internlm2-math-plus-1_8b\",\n",
    "    # \"internlm/internlm2-math-plus-20b\",\n",
    "    # \"internlm/internlm2-math-plus-7b\",\n",
    "    \n",
    "    # \"deepseek-ai/deepseek-math-7b-instruct\",\n",
    "    # \"deepseek-ai/deepseek-math-7b-rl\",\n",
    "    \n",
    "    # \"PowerInfer/SmallThinker-3B-Preview\",\n",
    "\n",
    "    # \"Skywork/Skywork-o1-Open-Llama-3.1-8B\"\n",
    "    # \"NovaSky-AI/Sky-T1-32B-Preview\" # the same as qwen series\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "print(len(model_list))\n",
    "\n",
    "for checkpoint in model_list:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "    print(tokenizer.bos_token)\n",
    "    print(tokenizer.eos_token)\n",
    "    print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint:  deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is $10.0000198\\cdot 5.9999985401\\cdot 6.9999852$ to the nearest whole number<｜Assistant｜>\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "checkpoint:  deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is $10.0000198\\cdot 5.9999985401\\cdot 6.9999852$ to the nearest whole number<｜Assistant｜>\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "checkpoint:  deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is $10.0000198\\cdot 5.9999985401\\cdot 6.9999852$ to the nearest whole number<｜Assistant｜>\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "checkpoint:  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is $10.0000198\\cdot 5.9999985401\\cdot 6.9999852$ to the nearest whole number<｜Assistant｜>\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "checkpoint:  deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is $10.0000198\\cdot 5.9999985401\\cdot 6.9999852$ to the nearest whole number<｜Assistant｜>\n",
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"model_chat_template.txt\", \"a\") as f:\n",
    "    for checkpoint in model_list:\n",
    "        print(\"checkpoint: \", checkpoint)\n",
    "        f.write(\"checkpoint: \" + checkpoint + \"\\n\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "        sbs_hard_prompt = \"\"\"Please reason step by step, and put your final answer within \\\\boxed{{}}.\"\"\"\n",
    "        question = \"What is $10.0000198\\\\cdot 5.9999985401\\\\cdot 6.9999852$ to the nearest whole number\"\n",
    "        if \"gemma\" in checkpoint or \"DeepSeek-R1-Distill\" in checkpoint:\n",
    "            messages = [ {\"role\": \"user\", \"content\": sbs_hard_prompt + \"\\n\\n\" + question}]\n",
    "        else:\n",
    "            messages = [{\"role\": \"system\", \"content\": sbs_hard_prompt}, {\"role\": \"user\", \"content\": question}]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        print(text)\n",
    "        print(tokenizer.bos_token)\n",
    "        print(tokenizer.eos_token)\n",
    "        print(\"-\" * 100)\n",
    "        f.write(text + \"\\n\")\n",
    "        f.write(\"-\" * 100 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_TEMPLATES = {\n",
    "    # Mistral Family (mistral-7b, ministral-8b, mistral-nemo, mistral-small, mathstral)\n",
    "    \"mistral\": {\n",
    "        \"template\": \"<s>[INST] {system_message}\\n\\n{user_message}[/INST]\",\n",
    "        \"models\": [\n",
    "            \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "            \"mistralai/Ministral-8B-Instruct-2410\", \n",
    "            \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "            \"mistralai/Mistral-Small-Instruct-2409\",\n",
    "            \"mistralai/Mathstral-7B-v0.1\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Qwen Family (all Qwen models including QwQ)\n",
    "    \"qwen\": {\n",
    "        \"template\": \"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        \"models\": [\n",
    "            \"Qwen/Qwen2.5-32B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-Math-7B-Instruct\",\n",
    "            \"Qwen/Qwen2.5-Math-1.5B-Instruct\",\n",
    "            \"Qwen/QwQ-32B-Preview\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Phi3 mini Family\n",
    "    \"phi3mini\": {\n",
    "        \"template\": \"<|system|>\\n{system_message}<|end|>\\n<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "        \"models\": [\n",
    "            \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "            \"microsoft/Phi-3.5-mini-instruct\"\n",
    "        ]\n",
    "    },\n",
    "    # Phi3 small Family\n",
    "    \"phi3small\": {\n",
    "        \"template\": \"<|endoftext|><|system|>\\n{system_message}<|end|>\\n<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "        \"models\": [\"microsoft/Phi-3-small-128k-instruct\"]\n",
    "    },\n",
    "    # Phi3 medium Family\n",
    "    \"phi3medium\": {\n",
    "        \"template\": \"<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "        \"models\": [\"microsoft/Phi-3-medium-128k-instruct\"]\n",
    "    },\n",
    "    # Phi-4\n",
    "    \"phi4\": {\n",
    "        \"template\": \"<|im_start|>system<|im_sep|>{system_message}<|im_end|><|im_start|>user<|im_sep|>{user_message}<|im_end|><|im_start|>assistant<|im_sep|>\",\n",
    "        \"models\": [\"microsoft/phi-4\"]\n",
    "    },\n",
    "\n",
    "    # Llama Family\n",
    "    \"llama\": {\n",
    "        \"template\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "        \"models\": [\n",
    "            \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "            \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "            \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Gemma Family\n",
    "    \"gemma\": {\n",
    "        \"template\": \"<bos><start_of_turn>user\\n{user_message}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "        \"models\": [\n",
    "            \"google/gemma-2-9b-it\",\n",
    "            \"google/gemma-2-2b-it\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # NuminaMath\n",
    "    \"numina\": {\n",
    "        \"template\": \"### Problem: {user_message}\\n### Solution: \",\n",
    "        \"models\": [\"AI-MO/NuminaMath-7B-CoT\"]\n",
    "    },\n",
    "\n",
    "    # InternLM Family\n",
    "    \"internlm\": {\n",
    "        \"template\": \"<s><|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        \"models\": [\n",
    "            \"internlm/internlm2_5-1_8b-chat\",\n",
    "            \"internlm/internlm2_5-7b-chat\",\n",
    "            \"internlm/internlm2_5-20b-chat\",\n",
    "            \"internlm/internlm2-math-plus-1_8b\",\n",
    "            \"internlm/internlm2-math-plus-7b\",\n",
    "            \"internlm/internlm2-math-plus-20b\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # DeepSeek Math\n",
    "    \"deepseek\": {\n",
    "        \"template\": \"<｜begin▁of▁sentence｜>{system_message}\\n\\nUser: {user_message}\\n\\nAssistant:\",\n",
    "        \"models\": [\n",
    "            \"deepseek-ai/deepseek-math-7b-instruct\",\n",
    "            \"deepseek-ai/deepseek-math-7b-rl\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # SmallThinker\n",
    "    \"smallthinker\": {\n",
    "        \"template\": \"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        \"models\": [\"PowerInfer/SmallThinker-3B-Preview\"]\n",
    "    },\n",
    "\n",
    "    # Skywork\n",
    "    \"skywork\": {\n",
    "        \"template\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "        \"models\": [\"Skywork/Skywork-o1-Open-Llama-3.1-8B\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define all unique chat templates\n",
    "CHAT_TEMPLATE_FORMATS = {\n",
    "    \"mistral_format\": \"<s>[INST] {system_message}\\n\\n{user_message}[/INST]\",\n",
    "    \n",
    "    \"qwen_format\": \"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \n",
    "    \"phi3mini_format\": \"<|system|>\\n{system_message}<|end|>\\n<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "    \n",
    "    \"phi3small_format\": \"<|endoftext|><|system|>\\n{system_message}<|end|>\\n<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "    \n",
    "    \"phi3medium_format\": \"<|user|>\\n{user_message}<|end|>\\n<|assistant|>\\n\",\n",
    "    \n",
    "    \"phi4_format\": \"<|im_start|>system<|im_sep|>{system_message}<|im_end|><|im_start|>user<|im_sep|>{user_message}<|im_end|><|im_start|>assistant<|im_sep|>\",\n",
    "    \n",
    "    \"llama_format\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "    \n",
    "    \"gemma_format\": \"<bos><start_of_turn>user\\n{user_message}<end_of_turn>\\n<start_of_turn>model\\n\",\n",
    "    \n",
    "    \"numina_format\": \"### Problem: {user_message}\\n### Solution: \",\n",
    "    \n",
    "    \"internlm_format\": \"<s><|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \n",
    "    \"deepseek_format\": \"<｜begin▁of▁sentence｜>{system_message}\\n\\nUser: {user_message}\\n\\nAssistant:\",\n",
    "    \n",
    "    # \"deepseek-r1-distill_format\" : \"<｜begin▁of▁sentence｜>{system_message}<｜User｜>{user_message}<｜Assistant｜>\"\n",
    "    \"deepseek-r1-distill_format\" : \"<｜begin▁of▁sentence｜><｜User｜>{user_message}<｜Assistant｜>\"\n",
    "}\n",
    "\n",
    "# Then map each model to its template format\n",
    "MODEL_TO_TEMPLATE = {\n",
    "    # Mistral Family\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": CHAT_TEMPLATE_FORMATS[\"mistral_format\"],\n",
    "    \"mistralai/Ministral-8B-Instruct-2410\": CHAT_TEMPLATE_FORMATS[\"mistral_format\"],\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\": CHAT_TEMPLATE_FORMATS[\"mistral_format\"],\n",
    "    \"mistralai/Mistral-Small-Instruct-2409\": CHAT_TEMPLATE_FORMATS[\"mistral_format\"],\n",
    "    \"mistralai/Mathstral-7B-v0.1\": \"mistral_format\",\n",
    "    \n",
    "    # Qwen Family\n",
    "    \"Qwen/Qwen2.5-32B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-14B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-0.5B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-Math-7B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/Qwen2.5-Math-1.5B-Instruct\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \"Qwen/QwQ-32B-Preview\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \n",
    "    # Phi Family\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\": CHAT_TEMPLATE_FORMATS[\"phi3mini_format\"],\n",
    "    \"microsoft/Phi-3.5-mini-instruct\": CHAT_TEMPLATE_FORMATS[\"phi3mini_format\"],\n",
    "    \"microsoft/Phi-3-small-128k-instruct\": CHAT_TEMPLATE_FORMATS[\"phi3small_format\"],\n",
    "    \"microsoft/Phi-3-medium-128k-instruct\": CHAT_TEMPLATE_FORMATS[\"phi3medium_format\"],\n",
    "    \"microsoft/phi-4\": CHAT_TEMPLATE_FORMATS[\"phi4_format\"],\n",
    "    \n",
    "    # Llama Family\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\": CHAT_TEMPLATE_FORMATS[\"llama_format\"],\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\": CHAT_TEMPLATE_FORMATS[\"llama_format\"],\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": CHAT_TEMPLATE_FORMATS[\"llama_format\"],\n",
    "    \n",
    "    # Gemma Family\n",
    "    \"google/gemma-2-9b-it\": CHAT_TEMPLATE_FORMATS[\"gemma_format\"],\n",
    "    \"google/gemma-2-2b-it\": CHAT_TEMPLATE_FORMATS[\"gemma_format\"],\n",
    "    \n",
    "    # NuminaMath\n",
    "    \"AI-MO/NuminaMath-7B-CoT\": CHAT_TEMPLATE_FORMATS[\"numina_format\"],\n",
    "    \n",
    "    # InternLM Family\n",
    "    \"internlm/internlm2_5-1_8b-chat\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \"internlm/internlm2_5-7b-chat\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \"internlm/internlm2_5-20b-chat\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \"internlm/internlm2-math-plus-1_8b\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \"internlm/internlm2-math-plus-7b\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \"internlm/internlm2-math-plus-20b\": CHAT_TEMPLATE_FORMATS[\"internlm_format\"],\n",
    "    \n",
    "    # DeepSeek Math\n",
    "    \"deepseek-ai/deepseek-math-7b-instruct\": CHAT_TEMPLATE_FORMATS[\"deepseek_format\"],\n",
    "    \"deepseek-ai/deepseek-math-7b-rl\": CHAT_TEMPLATE_FORMATS[\"deepseek_format\"],\n",
    "    \n",
    "    # SmallThinker\n",
    "    \"PowerInfer/SmallThinker-3B-Preview\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],  # Uses same format as Qwen\n",
    "    \n",
    "    # Skywork\n",
    "    \"Skywork/Skywork-o1-Open-Llama-3.1-8B\": CHAT_TEMPLATE_FORMATS[\"llama_format\"],\n",
    "    \n",
    "    # Sky-T1\n",
    "    \"NovaSky-AI/Sky-T1-32B-Preview\": CHAT_TEMPLATE_FORMATS[\"qwen_format\"],\n",
    "    \n",
    "    # DeepSeek-R1-Distill\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": CHAT_TEMPLATE_FORMATS[\"deepseek-r1-distill_format\"],\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": CHAT_TEMPLATE_FORMATS[\"deepseek-r1-distill_format\"],\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": CHAT_TEMPLATE_FORMATS[\"deepseek-r1-distill_format\"],\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": CHAT_TEMPLATE_FORMATS[\"deepseek-r1-distill_format\"],\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": CHAT_TEMPLATE_FORMATS[\"deepseek-r1-distill_format\"]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25_math_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
